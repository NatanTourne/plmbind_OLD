{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5torch\n",
    "import py2bit\n",
    "import random\n",
    "\n",
    "\n",
    "def get_chrom_number(chr):\n",
    "    try:\n",
    "        num = int(chr[3:])\n",
    "    except:\n",
    "        num = 100\n",
    "    return num\n",
    "\n",
    "bed_path = \"/home/data/shared/natant/Data/remap_merged_peaks.bed\"\n",
    "genome_path = \"/home/natant/Thesis-plmbind/Data/Genomes/hg38.2bit\"\n",
    "chrom = [1, 2]\n",
    "alts = False\n",
    "NOTchrom = None\n",
    "all_TFs = \"/home/natant/Thesis-plmbind/Thesis/utils/TF_split/TF_data_split/ALL_TFs.txt\"\n",
    "data = pd.read_csv(bed_path, sep = \"\\t\", header = None)\n",
    "data.head()\n",
    "\n",
    "\n",
    "TF_list = []\n",
    "with open(all_TFs) as f:\n",
    "    for TF in f:\n",
    "        TF_list.append(TF.strip())\n",
    "              \n",
    "prot_db = dict(zip(TF_list, range(len(TF_list))))\n",
    "\n",
    "tb = py2bit.open(genome_path)\n",
    "\n",
    "# define mapping for nucleotides:\n",
    "mapping = {\"A\": 0, \"T\": 1, \"C\": 2, \"G\": 3, \"N\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used chromosomes: \n",
      "['chr1', 'chr2']\n"
     ]
    }
   ],
   "source": [
    "Unique_chrom_names = list(tb.chroms())\n",
    "chrom_order = sorted(list(Unique_chrom_names), key=lambda x: get_chrom_number(x))\n",
    "print(\"Used chromosomes: \")\n",
    "if chrom != None:\n",
    "    chroms = [chrom_order[i-1] for i in chrom]\n",
    "    if alts == \"True\":\n",
    "        chroms = [i for i in chrom_order if i.split(\"_\")[0] in chroms]\n",
    "    print(chroms)\n",
    "elif NOTchrom != None:\n",
    "    NOTchroms = [chrom_order[i-1] for i in NOTchrom]\n",
    "    special_chroms = [i for i in chrom_order if i.split(\"_\")[0] in NOTchroms]\n",
    "    NOTchroms = NOTchroms + special_chroms\n",
    "    chroms_w_alts = [i for i in chrom_order if i not in NOTchroms]\n",
    "    chroms = [i for i in chroms_w_alts if len(i.split(\"_\"))==1]\n",
    "    if alts == \"True\":\n",
    "        chroms = chroms_w_alts[:]\n",
    "        \n",
    "    print(chroms)\n",
    "else:\n",
    "    raise SystemExit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\n",
      "gettin chrom ..\n",
      "chr2\n",
      "gettin chrom ..\n"
     ]
    }
   ],
   "source": [
    "sequence_per_chrom = []\n",
    "rows_per_chrom = []\n",
    "cols_per_chrom = []\n",
    "DNA_frames = []\n",
    "rows = []\n",
    "cols = []\n",
    "for chrom_name in chroms:\n",
    "    chrom_rows = []\n",
    "    print(chrom_name)\n",
    "    print('gettin chrom ..')\n",
    "    # get peaks for chrom\n",
    "    data_subset = data[data[0] == chrom_name]\n",
    "  \n",
    "    desired_length = 2048\n",
    "    \n",
    "    for ix, i in enumerate(range(len(data_subset))):\n",
    "        start, stop, TFs = data_subset.iloc[i][[1, 2, 3]]\n",
    "        delta = stop-start\n",
    "        if delta <= desired_length:\n",
    "            if delta < desired_length:\n",
    "                # NOG CHECKEN DAT HET JUIST IS\n",
    "                prefix = random.randint(0,desired_length-delta)\n",
    "                suffix = desired_length-delta-prefix\n",
    "                start = start - prefix\n",
    "                stop = stop + suffix\n",
    "            \n",
    "            # HIER\n",
    "            chrom_rows.append((chrom_name, start, stop))\n",
    "            cols.append([prot_db[i] for i in TFs.split(\",\")])\n",
    "            \n",
    "    chrom = np.array([mapping[l] for l in tb.sequence(chrom_name)], dtype=np.int8)\n",
    "    DNA_frames.extend([chrom[i[1]:i[2]] for i in chrom_rows])\n",
    "    rows.extend(chrom_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((len(rows), len(prot_db)), dtype=np.bool_)\n",
    "y.shape\n",
    "for i,TFs in enumerate(cols):\n",
    "    y[i,TFs] = True\n",
    "    \n",
    "from scipy.sparse import csr_matrix\n",
    "mat = csr_matrix(y) # Die matrix dan sparse maken\n",
    "mat.indices = mat.indices.astype(np.int16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<476292x1210 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 5539120 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476292"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DNA_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476292, 2048)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(DNA_frames).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <HDF5 group \"/0\" (1 members)>\n",
      "0/DNA <HDF5 dataset \"DNA\": shape (476292, 2048), type \"|i1\">\n",
      "1 <HDF5 group \"/1\" (1 members)>\n",
      "1/prots <HDF5 dataset \"prots\": shape (1210,), type \"|S13\">\n",
      "central <HDF5 group \"/central\" (3 members)>\n",
      "central/data <HDF5 dataset \"data\": shape (5539120,), type \"|b1\">\n",
      "central/indices <HDF5 dataset \"indices\": shape (5539120,), type \"<i4\">\n",
      "central/indptr <HDF5 dataset \"indptr\": shape (476293,), type \"<i4\">\n",
      "unstructured <HDF5 group \"/unstructured\" (1 members)>\n",
      "unstructured/nucleotide_mapping <HDF5 dataset \"nucleotide_mapping\": shape (5,), type \"|S1\">\n"
     ]
    }
   ],
   "source": [
    "f = h5torch.File(\"/home/natant/Thesis-plmbind/Thesis/utils/data_processing/test.h5\", \"w\")\n",
    "f.register(mat, axis=\"central\", mode = \"csr\", dtype_save = \"bool\", dtype_load=\"int64\")\n",
    "f.register(np.array(DNA_frames), axis = 0, name = \"DNA\", mode = \"N-D\", dtype_save = \"int8\", dtype_load=\"int64\")\n",
    "ix_to_prot = {v : k for k, v in prot_db.items()}\n",
    "prot_mapping = np.array([ix_to_prot[i] for i in range(len(prot_db))]).astype(bytes)\n",
    "f.register(prot_mapping, axis = 1, name = \"prots\", mode = \"N-D\", dtype_save = \"bytes\", dtype_load = \"str\")\n",
    "ix_to_nuc = {v : k for k, v in mapping.items()}\n",
    "nucleotide_mapping = np.array([ix_to_nuc[i] for i in range(len(ix_to_nuc))]).astype(bytes)\n",
    "f.register(nucleotide_mapping, axis = \"unstructured\", name = \"nucleotide_mapping\", mode = \"N-D\", dtype_save = \"bytes\", dtype_load = \"str\")\n",
    "\n",
    "f.visititems(print)\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90bcb56d9e608fd7a51bb085068b6a1764198772bb8025d4b6310f8e0a52840d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
