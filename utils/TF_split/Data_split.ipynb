{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import random\n",
    "random.seed(500)\n",
    "df = pd.read_csv(r\"/home/natant/Thesis-plmbind/Testing_ground/info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_families = list(df[\"DBD\"][[i not in [\"C2H2 ZF\", \"Homeodomain\", \"bHLH\"] for i in df[\"DBD\"]]].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_ZFs = df[\"HGNC symbol\"][df[\"DBD\"] == \"C2H2 ZF\"].to_list()\n",
    "random.shuffle(All_ZFs)\n",
    "ZNF_test = All_ZFs[:50]\n",
    "ZNF_val = All_ZFs[50:100]\n",
    "ZNF_train = All_ZFs[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_homeo = df[\"HGNC symbol\"][df[\"DBD\"] == \"Homeodomain\"].to_list()\n",
    "random.shuffle(All_homeo)\n",
    "Homeo_test = All_homeo[:5]\n",
    "Homeo_val = All_homeo[5:10]\n",
    "Homeo_train = All_homeo[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_bHLH = df[\"HGNC symbol\"][df[\"DBD\"] == \"bHLH\"].to_list()\n",
    "random.shuffle(All_bHLH)\n",
    "bHLH_test = All_bHLH[:5]\n",
    "bHLH_val = All_bHLH[5:10]\n",
    "bHLH_train = All_bHLH[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(other_families)\n",
    "test_families = other_families[:5]\n",
    "val_families = other_families[5:10]\n",
    "train_families = other_families[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_test = df[\"HGNC symbol\"][[i in test_families for i in df[\"DBD\"]]].to_list()\n",
    "rest_val = df[\"HGNC symbol\"][[i in val_families for i in df[\"DBD\"]]].to_list()\n",
    "rest_train = df[\"HGNC symbol\"][[i in train_families for i in df[\"DBD\"]]].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check!!\n",
    "len(rest_test + rest_val + rest_train + bHLH_test + bHLH_val + bHLH_train + Homeo_test + Homeo_val + Homeo_train + ZNF_test + ZNF_val + ZNF_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_TFs = ZNF_train + Homeo_train + bHLH_train + rest_train\n",
    "test_TFs = ZNF_test + Homeo_test + bHLH_test + rest_test\n",
    "val_TFs = ZNF_val + Homeo_val + bHLH_val + rest_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_TFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_TFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_TFs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open(\"/home/natant/Thesis-plmbind/Thesis/utils/TF_split/test_TFs\", \"wb\") as f: # \"wb\" because we want to write in binary mode\n",
    "    pickle.dump(test_TFs, f)\n",
    "with open(\"/home/natant/Thesis-plmbind/Thesis/utils/TF_split/val_TFs\", \"wb\") as f: # \"wb\" because we want to write in binary mode\n",
    "    pickle.dump(val_TFs, f)\n",
    "with open(\"/home/natant/Thesis-plmbind/Thesis/utils/TF_split/train_TFs\", \"wb\") as f: # \"wb\" because we want to write in binary mode\n",
    "    pickle.dump(train_TFs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = [\"C2H2 ZF\", \"C2H2 ZF\", \"C2H2 ZF\", \"Homeodomain\", \"Homeodomain\", \"Homeodomain\", \"bHLH\", \"bHLH\", \"bHLH\"] + test_families + val_families + train_families\n",
    "target = [\"Train\", \"Val\", \"Test\", \"Train\", \"Val\", \"Test\",\"Train\", \"Val\", \"Test\"] + [\"Test\"]*len(test_families) + [\"Val\"]*len(val_families) + [\"Train\"]*len(train_families)\n",
    "value = [len(ZNF_train), len(ZNF_val), len(ZNF_test), len(Homeo_train), len(Homeo_val), len(Homeo_test), len(bHLH_train), len(bHLH_val), len(bHLH_test)] + [len(df[\"HGNC symbol\"][df[\"DBD\"] == i]) for i in test_families] + [len(df[\"HGNC symbol\"][df[\"DBD\"] == i]) for i in val_families] + [len(df[\"HGNC symbol\"][df[\"DBD\"] == i]) for i in train_families]\n",
    "sankey_df = pd.DataFrame({\"source\": source, \"target\": target, \"value\": value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349c195954b142e789abb4c52d111c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SankeyWidget(layout=Layout(height='1000', width='1000'), links=[{'source': 'C2H2 ZF', 'target': 'Train', 'valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipysankeywidget import SankeyWidget\n",
    "from ipywidgets import Layout\n",
    "layout = Layout(width=\"1000\", height=\"1000\")\n",
    "SankeyWidget(links=sankey_df.to_dict('records'), layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = [\"C2H2 ZF\", \"C2H2 ZF\", \"C2H2 ZF\", \"Homeodomain\", \"Homeodomain\", \"Homeodomain\", \"bHLH\", \"bHLH\", \"bHLH\"] + [\"test_families\", \"val_families\", \"train_families\"]\n",
    "target = [\"Train\", \"Val\", \"Test\", \"Train\", \"Val\", \"Test\",\"Train\", \"Val\", \"Test\"] + [\"Test\"] + [\"Val\"] + [\"Train\"]\n",
    "value = [len(ZNF_train), len(ZNF_val), len(ZNF_test), len(Homeo_train), len(Homeo_val), len(Homeo_test), len(bHLH_train), len(bHLH_val), len(bHLH_test)] + [len(rest_test), len(rest_val), len(rest_train)]\n",
    "sankey_df = pd.DataFrame({\"source\": source, \"target\": target, \"value\": value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6b2ad44c9b42a4949c8df20b329015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SankeyWidget(links=[{'source': 'C2H2 ZF', 'target': 'Train', 'value': 367}, {'source': 'C2H2 ZF', 'target': 'Vâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipysankeywidget import SankeyWidget\n",
    "from ipywidgets import Layout\n",
    "SankeyWidget(links=sankey_df.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'big 3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/Thesis/lib/python3.10/site-packages/pandas/core/indexes/base.py:3629\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3629\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3630\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.conda/envs/Thesis/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/Thesis/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'big 3'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m#nodes['customers'].partition = customers_by_name\u001b[39;00m\n\u001b[1;32m     32\u001b[0m sdd \u001b[39m=\u001b[39m SankeyDefinition(nodes, bundles, ordering)\n\u001b[0;32m---> 33\u001b[0m weave(sdd, sankey_df)\u001b[39m.\u001b[39mto_widget()\n",
      "File \u001b[0;32m~/.conda/envs/Thesis/lib/python3.10/site-packages/floweaver/weave.py:52\u001b[0m, in \u001b[0;36mweave\u001b[0;34m(sankey_definition, dataset, measures, link_width, link_color, palette, add_elsewhere_waypoints)\u001b[0m\n\u001b[1;32m     47\u001b[0m bundle_flows, unused_flows \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mapply_view(\n\u001b[1;32m     48\u001b[0m     sankey_definition\u001b[39m.\u001b[39mnodes, bundles2, sankey_definition\u001b[39m.\u001b[39mflow_selection\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     51\u001b[0m \u001b[39m# Calculate the results graph (actual Sankey data)\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m GR, groups \u001b[39m=\u001b[39m results_graph(\n\u001b[1;32m     53\u001b[0m     GV2,\n\u001b[1;32m     54\u001b[0m     bundle_flows,\n\u001b[1;32m     55\u001b[0m     flow_partition\u001b[39m=\u001b[39;49msankey_definition\u001b[39m.\u001b[39;49mflow_partition,\n\u001b[1;32m     56\u001b[0m     time_partition\u001b[39m=\u001b[39;49msankey_definition\u001b[39m.\u001b[39;49mtime_partition,\n\u001b[1;32m     57\u001b[0m     measures\u001b[39m=\u001b[39;49mmeasures,\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     60\u001b[0m \u001b[39m# Default link width is same as default measure\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39mif\u001b[39;00m link_width \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/Thesis/lib/python3.10/site-packages/floweaver/results_graph.py:82\u001b[0m, in \u001b[0;36mresults_graph\u001b[0;34m(view_graph, bundle_flows, flow_partition, time_partition, measures)\u001b[0m\n\u001b[1;32m     80\u001b[0m gf \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mflow_partition\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m flow_partition \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     81\u001b[0m gt \u001b[39m=\u001b[39m time_partition \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m edges \u001b[39m=\u001b[39m group_flows(flows, v, gv, w, gw, gf, gt, measures)\n\u001b[1;32m     83\u001b[0m \u001b[39mfor\u001b[39;00m _, _, _, d \u001b[39min\u001b[39;00m edges:\n\u001b[1;32m     84\u001b[0m     d[\u001b[39m'\u001b[39m\u001b[39mbundles\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mbundles\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/Thesis/lib/python3.10/site-packages/floweaver/results_graph.py:147\u001b[0m, in \u001b[0;36mgroup_flows\u001b[0;34m(flows, v, partition1, w, partition2, flow_partition, time_partition, measures)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mmeasure must be str, list, dict or callable\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    146\u001b[0m e \u001b[39m=\u001b[39m flows\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m--> 147\u001b[0m set_partition_keys(e, partition1, \u001b[39m'\u001b[39;49m\u001b[39mk1\u001b[39;49m\u001b[39m'\u001b[39;49m, v \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m^\u001b[39;49m\u001b[39m'\u001b[39;49m, process_side\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msource\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    148\u001b[0m set_partition_keys(e, partition2, \u001b[39m'\u001b[39m\u001b[39mk2\u001b[39m\u001b[39m'\u001b[39m, w \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m^\u001b[39m\u001b[39m'\u001b[39m, process_side\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    149\u001b[0m set_partition_keys(e, flow_partition, \u001b[39m'\u001b[39m\u001b[39mk3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/Thesis/lib/python3.10/site-packages/floweaver/results_graph.py:170\u001b[0m, in \u001b[0;36mset_partition_keys\u001b[0;34m(df, partition, key_column, prefix, process_side)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[39mif\u001b[39;00m dim\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mprocess\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m process_side:\n\u001b[1;32m    169\u001b[0m         dim \u001b[39m=\u001b[39m process_side \u001b[39m+\u001b[39m dim[\u001b[39m7\u001b[39m:]\n\u001b[0;32m--> 170\u001b[0m     q \u001b[39m=\u001b[39m q \u001b[39m&\u001b[39m df[dim]\u001b[39m.\u001b[39misin(values)\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(q \u001b[39m&\u001b[39m seen):\n\u001b[1;32m    172\u001b[0m     dup \u001b[39m=\u001b[39m df[q \u001b[39m&\u001b[39m seen]\n",
      "File \u001b[0;32m~/.conda/envs/Thesis/lib/python3.10/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.conda/envs/Thesis/lib/python3.10/site-packages/pandas/core/indexes/base.py:3631\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3630\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3631\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3632\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3633\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3634\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'big 3'"
     ]
    }
   ],
   "source": [
    "from floweaver import *\n",
    "nodes = {\n",
    "    'Families': ProcessGroup([\"C2H2 ZF\", \"Homeodomain\", \"bHLH\", \"test_families\", \"val_families\", \"train_families\"]),\n",
    "    'Targets': ProcessGroup(['Train', 'Val', 'Test']),\n",
    "}\n",
    "\n",
    "ordering = [\n",
    "    ['Families'],       # put \"farms\" on the left...\n",
    "    ['Targets'],   # ... and \"customers\" on the right.\n",
    "]\n",
    "\n",
    "bundles = [\n",
    "    Bundle('Families', 'Targets'),\n",
    "]\n",
    "\n",
    "families_with_other = Partition.Simple('big 3', [\n",
    "    'C2H2 ZF',  # the groups within the partition can be a single id...\n",
    "    'Homeodomain',\n",
    "    'bHLH',\n",
    "    ('other', ['test_families', 'val_families', 'train_families']),   # ... or a group\n",
    "])\n",
    "\n",
    "# This is another partition.\n",
    "customers_by_name = Partition.Simple('process', [\n",
    "    'James', 'Mary', 'Fred', 'Susan'\n",
    "])\n",
    "\n",
    "# Update the ProcessGroup nodes to use the partitions\n",
    "nodes['Families'].partition = families_with_other\n",
    "#nodes['customers'].partition = customers_by_name\n",
    "\n",
    "sdd = SankeyDefinition(nodes, bundles, ordering)\n",
    "weave(sdd, sankey_df).to_widget()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90bcb56d9e608fd7a51bb085068b6a1764198772bb8025d4b6310f8e0a52840d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
