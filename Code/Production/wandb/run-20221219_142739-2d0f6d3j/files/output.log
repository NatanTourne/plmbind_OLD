/home/natant/.conda/envs/Thesis/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/natant/.conda/envs/Thesis/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/natant/Thesis/Data/Model_checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]
  | Name          | Type              | Params
----------------------------------------------------
0 | loss_function | BCEWithLogitsLoss | 0
1 | train_acc     | BinaryAccuracy    | 0
2 | val_acc       | BinaryAccuracy    | 0
3 | test_acc      | BinaryAccuracy    | 0
4 | train_AUROC   | MultilabelAUROC   | 0
5 | val_AUROC     | MultilabelAUROC   | 0
6 | test_AUROC    | MultilabelAUROC   | 0
7 | embedding     | Embedding         | 20
8 | conv_net      | Sequential        | 6.6 M
----------------------------------------------------
6.6 M     Trainable params
20        Non-trainable params
6.6 M     Total params
26.309    Total estimated model params size (MB)
Sanity Checking DataLoader 0:   0%|                                                                                                                                                           | 0/2 [00:00<?, ?it/s]
/home/natant/.conda/envs/Thesis/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/natant/.conda/envs/Thesis/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score

Epoch 0:   0%|                                                                                                                                                                              | 0/120 [00:00<?, ?it/s]
/home/natant/.conda/envs/Thesis/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
























































Epoch 0:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 100/120 [01:53<00:22,  1.14s/it, loss=0.0251, v_num=6d3j]


































































Epoch 1:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 100/120 [01:52<00:22,  1.12s/it, loss=0.0205, v_num=6d3j]




































































Epoch 2:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 100/120 [01:54<00:22,  1.15s/it, loss=0.0181, v_num=6d3j]




































































Epoch 3:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 100/120 [01:54<00:22,  1.15s/it, loss=0.0172, v_num=6d3j]



































































Epoch 4:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 100/120 [01:54<00:22,  1.15s/it, loss=0.0166, v_num=6d3j]




































































Epoch 5:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 100/120 [01:54<00:22,  1.15s/it, loss=0.0161, v_num=6d3j]




































































Epoch 6:  84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 101/120 [01:55<00:21,  1.15s/it, loss=0.0175, v_num=6d3j]




































































Epoch 7:  84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 101/120 [01:55<00:21,  1.15s/it, loss=0.0152, v_num=6d3j]



































































Epoch 8:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 100/120 [01:54<00:22,  1.15s/it, loss=0.0152, v_num=6d3j]




































































Epoch 9:  84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 101/120 [01:55<00:21,  1.15s/it, loss=0.0146, v_num=6d3j]



































































Epoch 10:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 100/120 [01:54<00:22,  1.15s/it, loss=0.0136, v_num=6d3j]




































































Epoch 11:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 100/120 [01:54<00:22,  1.15s/it, loss=0.0131, v_num=6d3j]




































































Epoch 12:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 100/120 [01:54<00:22,  1.15s/it, loss=0.0137, v_num=6d3j]



































































Epoch 13:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 100/120 [01:54<00:22,  1.14s/it, loss=0.0136, v_num=6d3j]




































































Epoch 14:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 100/120 [01:54<00:22,  1.15s/it, loss=0.0138, v_num=6d3j]




































































Epoch 15:  84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 101/120 [01:55<00:21,  1.15s/it, loss=0.0126, v_num=6d3j]




































































Epoch 16:  84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 101/120 [01:55<00:21,  1.15s/it, loss=0.0128, v_num=6d3j]



































































Epoch 17:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 100/120 [01:54<00:22,  1.15s/it, loss=0.0125, v_num=6d3j]




































































Epoch 18:  84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 101/120 [01:55<00:21,  1.15s/it, loss=0.0121, v_num=6d3j]




































































Epoch 19:  84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 101/120 [01:55<00:21,  1.15s/it, loss=0.0119, v_num=6d3j]


































Epoch 20:  33%|██████████████████████████████████████████████▎                                                                                            | 40/120 [00:45<01:31,  1.15s/it, loss=0.0101, v_num=6d3j]
/home/natant/.conda/envs/Thesis/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  rank_zero_warn("Detected KeyboardInterrupt, attempting graceful shutdown...")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]
/home/natant/.conda/envs/Thesis/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.






























































Testing DataLoader 0:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 99/100 [02:01<00:01,  1.22s/it]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]
/home/natant/.conda/envs/Thesis/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
Testing DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:02<00:00,  1.23s/it]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m        Test metric        [22m┃[1m       DataLoader 0        [22m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m        test_AUROC         [39m│[35m    0.5983999371528625     [39m│
│[36m         test_acc          [39m│[35m    0.9966089129447937     [39m│
│[36m         test_loss         [39m│[35m    0.03971165046095848    [39m│
└───────────────────────────┴───────────────────────────┘










Predicting DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:20<00:00,  1.03s/it]
tensor([0.7481, 0.7708, 0.6784, 0.7786, 0.7831, 0.7628, 0.8415, 0.5946, 0.5719,
        0.0000, 0.0000, 0.7036, 0.8284, 0.0000, 0.6356, 0.0000, 0.6529, 0.0000,
        0.0000, 0.0000, 0.9146, 0.6788, 0.8055, 0.5266, 0.6989, 0.8097, 0.0000,
        0.0000, 0.9045, 0.0000, 0.6763, 0.5853, 0.0000, 0.0000, 0.2316, 0.0000,
        0.7174, 0.7628, 0.0000, 0.6473, 0.8582, 0.6270, 0.0000, 0.7496, 0.0000,
        0.4160, 0.0000, 0.0000, 0.0000, 0.7387, 0.9937, 0.0000, 0.3803, 0.7293,
        0.7152, 0.0000, 0.2848, 0.8598, 0.8459, 0.7226, 0.7277, 0.0000, 0.7152,
        0.0000, 0.7152, 0.7814, 0.7152, 0.6995, 0.0000, 0.0000, 0.0000, 0.0000,
        0.6552, 0.7152, 0.7152, 0.8103, 0.0000, 0.8357, 0.0000, 0.0000, 0.0000,
        0.4945, 0.6436, 0.8571, 0.7865, 0.8096, 0.0000, 0.9729, 0.8027, 0.6819,
        0.7230, 0.7883, 0.5992, 0.0000, 0.0000, 0.8127, 0.6761, 0.9186, 0.0000,
        0.9718, 0.0000])